# Template for Privacy TF Minutes - Wed, DD Month 2022

* Present: Nick, Jeffrey, Christine, Wendy, Don, Robin, Sam, Pete
* Regrets: Torgo, Amy

## [PRs](https://github.com/w3ctag/privacy-principles/pulls?q=is%3Aopen+is%3Apr+sort%3Acreated-asc)

### [Added notifications principles](https://github.com/w3ctag/privacy-principles/pull/132) (torgo)

Jeffrey: I left some minor edits, but I think it's basically ready to merge.

Don: I like it. I like the "sufficient knowledge" material. Looks good.

Nick: Maybe too specific. UI for letting users audit. Maybe ok, but maybe a browser will come up with another way to let users revoke. Quality metric on initial request, but maybe there should be a metric on all notifications.

Jeffrey: Would like to generalize to interruptions, but this is a good starting point, and we can edit from here.

Robin: Agree.

Nick: We have a principle here for sites, and we should talk about whether we want to be this strict. I think this is rarely followed. Do we have a plausible pathway to getting here?

Jeffrey: I think things like chat sites do follow this, but it's reasonable to call out sites that are abusing it. No way to enforce this other than shame.

Jeffrey: Any objections to merging?

Jeffrey: I'll make the small edits. Nick to file an issue to capture some things from above.

### [first go at reworking private data section into discrete principals](https://github.com/w3ctag/privacy-principles/pull/133) (pes10k)

Pete: Same content as we talked about last week, but now in PR form.

Pete: Second principle says it's hard to distinguish sensitive from non-sensitive data, but that doesn't flow with the next section that's about sensitive data.

Robin: Put that principle in the sensitive data section.

Pete: "Surprise, there's no such thing!" is a little odd.

Robin: There's data that's clearly sensitive. And a principle that UAs shouldn't guess that things might not be sensitive.

Christine: One way to do the segue: all personal data is sensitive, but some jurisdictions have a policy that says some categories should be given special protections. Be aware that some types of data may need some extra protections. Often this is called "sensitive" data.

Pete: I dig that.

Nick: One way to understand this is that maybe you're making the point that *browsers* shouldn't guess which pieces of data are sensitive or not, but at the specification level, we can recognize that some data types are likely to be sensitive. E.g. we can't determine that any particular piece of location data is actually sensitive, but location data is often sensitive so we'd put in extra protections. Alternative is to treat all data the same?

Pete: Worried about a suggestion that there might be personal data that's not sensitive.

Nick: "Sensitive" is a way to describe a data type, which might help us determine permission levels and review specs. But we can't determine how secret a particular piece of data is.

Don: UA can't determine it, because the person could have interactions with the server-side party that the browser isn't aware of. Might think that "you like this book better than this other book", but you don't know whether the same party has offline data for which that would be the last missing piece. Information the party has, and information the browser facilitates sharing, and because the browser can't see all interactions, browser can't tell if this is the sensitive piece. Might be clearest to not talk about sensitive information at all, and say all information is potentially sensitive.

Jeffrey: Maybe "just because a piece of data isn't called sensitive doesn't mean it's ok to share it."

[Christine in chat: or "use it or collect it", not just sharing]

Robin: Also warn people that data that doesn't seem scary at first, is often subject to inferences that lead to sensitive data. E.g. reading history. URL, timestamp, how sensitive is that? But can reliably infer sensitive characteristics like race and gender.

Sam: Value in saying "you can guess whether something's sensitive, but you have to recognize that a guess is the best you can do."

Nick: Call the following section "sensitive data types"? There is some text that's getting at this. "A piece of data might have different sensitivities for different people."

Pete: Even I might not be able to predict whether a piece of my data will be sensitive tomorrow.

Christine: In our guidance, we want both high level principles but also practical. Nick's point about data categories: we'd say any kind of geolocation data should only be moved around in encrypted context. There's other sensitive data that should follow that rule. Don't know where we've got that level of guidance.

Jeffrey: We do restrict some obviously-sensitive data earlier than the less-sensitive data. E.g. we blocked geolocation-over-http earlier than we tried to block form submission over http.


Pete: I do disagree. Some data is more obviously sensitive than others, but even the things that seem clearly on one side are surprisingly often not.

Nick: Blocking form submission over http is our long-term goal.

Pete: Maybe talk about the ease of abuse? Geolocation isn't more or less sensitive, but easier to exploit.

Christine: Say that all personal data should be treated sensitively/protected.

Nick: Don't think we wrote the sensitive categories to say this is all the data you should protect.

Jeffrey: We should be sure not to imply that you don't need to protect "non-sensitive" data, and also not to imply that it's inappropriate to focus on more-sensitive data before you can afford to protect all data.

Pete: Don't mean that all data should be protected in the same way.

Don: There's no way to avoid people reading this to say that they can do whatever they want with something we call "non-sensitive".

Jeffrey: Next steps for PR? I need to do an editing pass, but it is generally ready to merge?

Nick: Can we decide what to do with principle #2?

Robin: Merge the two subsections, to avoid implying data types are distinct.

Nick: Seems like this deletes a lot of text. Don't really like deleting all of this. Don't know that we agree on the first principle.

Pete: I don't mean to actually delete the full text, just trying to focus on the principles.

Nick: Ok, then moving it around makes sense.

Jeffrey: I do still need to make sure the first principle works, but it looks basically ok. Is Pete's next step to re-add the text and get the PR in a shape ready to merge?

Robin: In the first principle, there's a lot of people who are surprised that if they access text on a page, the page knows about it. The "reasonableness" criterion might only work for people who are pretty familiar with technology, and not other people. Some people also thought that opening a search result link opened it "on" the search engine, which would give permission for the engine to keep tracking you forever. So this gives bad results in both directions.

Nick: Reporting happened, and so browsers added APIs specifically for that, and we probably won't convince people to remove those. I'm interested in principles that we can get people to move to.

Pete: If we think something's a good privacy property, but we won't get people to follow it, and so we shouldn't mention it, I wouldn't be happy.

Nick: We're looking at what's feasible for the web. There are properties that we don't think we can accomplish. E.g. websites learning that you've visited them.

Don: There are multiple audiences for this document. Some lower-profile surveillance marketers who'll pay little attention. Other implementers are doing things in a public way, often through W3C, who will refer to this. Just because one least-attentive audience won't do it, doesn't mean we won't have influence with other higher-profile audiences.



Jeffrey: This document is just a baseline for discussions, so it's ok if the "reasonableness" test can sometimes lead in the wrong direction, because

Nick: Can we give some guidance about APIs where a UA shares data because they think that if they don't, they think the website will share data anyway. E.g. "No UA strings" because users don't know they're being shared, and they're not needed for the immediate goal.

Pete: "reasonableness" means a lot of things, but it doesn't seem unreasonable for the site to know I'm visiting in Safari.

Nick: But they also don't need that for their immediate goal.

Pete: E.g. "download the mac version of this binary" Don't think people tend to think the browser is a completely isolated sandbox.

Jeffrey: UA string might not be a good example, because if we remove it, it tends to break the functionality of sites, not just analytics.

Robin: If we look at the UA string, it's 25 years old and deeply encrusted. This specific layer might not want to provide analytics-specific principles. Maybe an analytics WG would want to refine that. E.g. a group standardizing something like what AMP does for declarative analytics. Maybe it'd be ok to share data in an IPA-like way.

Nick: Sorry if I got us confused with the UA string. But we do have recent functionality for which the question is relevant.

Jeffrey: This is something where I should go ask my teammates about where we think the dividing line should be. I think it is appropriate to share *some* non-sensitive information to help sites debug or tailor their effort toward their actual users, but I don't know exactly where the dividing line is.

Don: Think about privacy labor, when we replace old things with fancy things. Could put a lot of cognitive burden on the user to figure out what's going on.

[...]

Nick: Do we have a response when browsers say "harmful things are happening, and we'll provide a less-harmful way to do it"

Pete: None off the top of my head. I'm ok if this document doesn't answer those questions.

Robin: I wouldn't expect this document to have this answer written out, but have we provided enough material for another group to use the principles to try to apply them to specific cases like "beacon v2", to help them resolve it in a good way.

Nick: I do like that goal. The current text would seem to prohibit this

Robin: If we think the text prohibits something that there's consensus that we need to do, we have a bug in the text. I'm focusing on the PATCG. In the principles document, we warn against consent and opt-in, but we don't say "never use it". E.g. text box for signing up for email. But in PATCG, maybe we could say consent is never appropriate for some use cases. In the other direction, we're never supposed to share private data, but in the IPA case, maybe you learn that someone has a 0.03% chance of being in a group, and given the limits, we find that this is safe, so we're comfortable with it.

Jeffrey: I do support harm reduction in general, and want to make sure our text doesn't seem to prohibit it.


Nick: Third principle: data minimization, which is great. Let's make sure not to duplicate it.


Pete: I'll give people a few days to read principles and then add back explanatory text.

Pete: Robin, did you want me to merge in the sensitive data section?

Robin: If you have the energy, yes please. But you could get the rest of it into shape and then merge later, that's fine too. Don't want to delay the PR.


### [Refine and clarify the definitions of first and third parties](https://github.com/w3ctag/privacy-principles/pull/139) (jyasskin)

Jeffrey: Probably not enough time to discuss today, but I made Nick's changes.

Robin: I'm ok with 139 as it is.

Nick: I'll review this.

### [Discuss tensions between principles](https://github.com/w3ctag/privacy-principles/pull/105) (jyasskin)

Jeffrey: Probably not enough time to discuss today, but I made Christine's changes.

Christine: I think it's ok to merge. will continue to refine wording.

Jeffrey: I would love to merge this. Any objections?

[No objections]

Jeffrey: Will merge!


