# TAG Privacy Principles Task Force, 18 May 2022

Present: Jeffrey, Dan, Sam, Don, Shubhie, Wendy, Pete, Tess, Christine

Regrets: Robin, Amy

## https://github.com/w3ctag/privacy-principles/pull/158

Jeffrey: made changes suggested last time - incentives to do good thing.  Wendy still has concern about guessing about second order effects.  When someone has done the investigation to find the 2nd order effects doing something with that shouldn't be against the principles.

Wendy: appreciate - important part of the dialogue that follows from this doc - I just don't think we want to try to get the consensus in this document. 

Don: Don't like the direction this is going... "Bad things might happen and we can prevent really bad things by doing somewhat risky things" - we could make the document much longer and less clear going this direction.

Jeffrey: want to leave the door open for patcg - private advertising technology CG... tradeoff to consider.. not guidance on how to make the tradeoff...

Pete: I feel nervous about the future prediction this requires... you need to be able to predict 3 steps in the future... 

Don: i can make a PR that says "user agents should not enable slightly creepy tracking tech because that will encourage marketers to develop skills based on creepy tracking and start to demand even creepier technologies to make those skills more valuable" - "if we can do one more thing then we can get more data than IPA"... not sure about the idea that throwing a little thing of value to your adversary will discourage them coming after you for more?

Jeffrey: example of the Fugu project - do some things that allow some features but don't allow the risky features - e..g. bluetooth mac accresses.

Shubhie: on prediction - we have market knowledge... we have a good idea of where the movemet is...

Pete: there's a long list of "we don't have this feature the web will die"...

Jeffrey: we're not going to evaluate them perfectly...

Dan: not comfortable... might give some new things a free pass? 

Jeffrey: we need to consider how to achieve as many of the principles as possible in the long run.

Don: there might be a way to split the difference... the extreme position : browsers should trick the user a little bit in order to avoid having some other platform trick them a lot. How about : browsers should share information on behalf of the user but if it passes the test of acting in a way that the user would have chosen to do if they were doing it themselves.  Some attribution tracking is something users would expect to do.  Customer surveys for example.  Implementing a data exchange that the user would choose to do. (asking "where did you hear about us" and the user fills in "I saw your ad on example.com")

Jeffrey: that touches on the discussion on the other PR - what the user would do if it didn't eat into time they were using for other stuff.

Pete: I disagree with the interpretation Don said... It's an impossible to say "what would this person do if they had unlimited time"... 2.. certainly some people won't fill out that survey so we shouldn't make a platform decision that assumes everyone would.

Dan: [long thing about web payment]

Jeffrey: that's not like this because it's more often... user might have given voluntarily if they had had the time to think about it... Not going to be an obvious choice... we don't know.

Christine: what kind of info?

Jeffrey: the example is IPA - "where did you see this ad" effectively? 

Christine: i am ome of the ones who doesn't want to answer that...

Wendy: collective privacy vs individual choices... the choice of a platform steward for overall privacy optimization might not match an individual's privacy preferences...  Yet another reason why this seems complicated.  Definitely has a place in the discussion.

Don: not just the preferences about sharing own information... preferences info not be revealued because someone else shared information. if you have a disability you don't want to be discriminiated against when hiring...you don't want people who don't have that disability sharing their details on a job posting site, even if they would consent to).

Jeffrey: channeling robin in cases of collective privacy you need collective governance to make privacy decisions... USer agents should work with a standards body to make this kind of decision.

Jeffrey: we can do better than the offline world - you don't get "this user saw the ad in this place" - you get "% chance they saw it in this place"...

Don: we're not just asking the user to sign up for the attribution system as described in the PDF. We're asking them to install real world code that has properties that may or may not match the PDF. Real code could have a flaw in it that does enable sharing of info that's not in line with the system as described. That user is not being asked to comprehend a PDF full of math and decide "do I trust IPA's math" they're being asked to comprehend the math and then comprehend whether a complex codebase accurately implements the math.

Jeffrey: I think we can put bugs out of scope... browsers sometimes have bugs. intent if the system is what mostly matters.

Don: We're asking the user to accept complexity and risk. There is always a tradeoff between risk and functionality. If a new browser feature lets me do a video conference, I might decide that it is useful for me and i will choose to accept the risk of the additional complexity. Not sure if I would accept browser features that are not for me.

Jeffrey: but it's for the benefit in the long term.

Pete: I don't agree... a site I want to support at one point.. might not be a site i want to support moving forward.

Hypothetical note from someone: i choose not to buy wine from a strore that scans my drivers' license.

Jeffrey: possible to expose in a way that a site is using these APIs so a user can make informed decisiom.

Don: i don't want to have the assumption that "additional tracking delivers additional value in terms of ad supported content" in this document, because there are different points of view on the economics of advertising.  Some of the highest-value ad-supported media are the least trackable. There's a lot of complex literature on the economics of advertising that doesn't line up with the framing that "additional info makes an ad supported medium more valuable".

Jeffrey: i'm hearing the idea of making longer term tradeoffs needs more work.

Pete: ...figure out what the bounds are... rule out some places... what kind of trade-offs would be acceptable.

Jeffrey: hard to say without expanding the text a lot.

Shubhie: did we talk about speaking in terms of user goals?

## https://github.com/w3ctag/privacy-principles/pull/162

Jeffrey: current state is to relate to user's goals... better ways to frame this... caputre which goals to support?

Shubhie: is this a place where we can expand on users' goals... 

Pete: worried ...

Christine: I like the generality of users' goals so it can be applied in different circumstances...  Would be difficult to articulate what users' goals might be.  

Sam: I prefer ... immediate and overt...  you should only share this if the user ]

Dan: overt or reasonable makes sense...  Some might say "you signed a 17 page Ts & Cs that says xxx" 

Christine: I was concerned that if you make it immediate and overt that you might not honor users' goals ... "they weren't overt about it so I assumed X"...

Jeffrey: I think we've covered Dan's concern about the 17 page agreement...  counter-argument is it 't not reasonable anticipation...

Christine: fine print sometimes says "we can change the price at any time" ... they got in trouble.

Shubhie: 2 goals... what the users are trying to accomplish on that web site... or have a relationship with... then there's a separate aspect of what is the tracking aspect.    The former seems like reasonable and uncotravertial... user flows... 2nd part is how can users might reason about ... convinving them to share... As a user agent, trying to reason about... part of this principles doc trying to establish how UAs should think about it..

Dan: some might say that the latter is part of the former...

Don: The actual site maintainer me be short of information, too. May have put third-party JavaScript on their site without understanding data practices of the third party.

Shubhie: could we have some text about the former... the potentially contraversial thing is the engagement aspect... talking about a user journey on the web and what that means... or pointing to another doc that talks about that. not all user journeys are "drive by" a lot of web usage is web pages used every day.

Pete: agree it's difficult to nail down.. keep conservative about what the goals are here... I li

Christine suggestes: "ser agents should not assume a user reasonably anticipates being tracked when they visit a website."

Pete: i think the direction is good.

Christine: for example, x y and z... 

Pete: do we have consensus?

Jeffrey: enumerating some examples might help us find consensus.  One concrete example is performance measurement... site wants to measure "is this page slow".  The user has a goal of wanting the web page to be responsive...   I'm aware there is disagreement about whether it's OK to send performance metrics....  

Pete: depends on the details... no backstop of how much performance data is acceptable...

Dan: shouldn't the web site ask you if you're ok to send performance metrics?

Don: privacy labour - if asking the question puts cognitive load on the user... careful when you ask for consent?

Tess: look at OSs that have analytics requests... at OS install time... do you want to share analytics info with [co] or with 3rd party developers (then never asks again)? one-off vs every time you go to a web site... If you want to do one-off question like "browser share performance data" .. you need that boundary. because detailed perf data is the same ad fingerprinting.

Pete: yes

Shubhie: any prior art from native apps?  A PWA install.. the user is already doing work for a site that they have a relationship with. Is that an angle of inetrest here?  

Tess: I think think the vast majority of web sites aren't ... so wary of limiting ...

Christine: can we add .. when in doubt, apply the most privacy respecting approach.  

Dan: err on the side of privacy.

Jeffrey: there is always doubt.

Christine: since this is a privacy document we should err on the side of privacy. 

Dan: can we priortize .. 1st order cases...

Jeffrey: I think we do have agreement that it's OK to share the user's address when the web site wants to ship something to you... Even the address is interesting ... web sites can easily join you acrosss sites when they have your address...

Jeffrey: I think considering longer term goals is important... 

Shubbie: I can at least write a text in another doc...  makes sense for it to go in this doc... 
