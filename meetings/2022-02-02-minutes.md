# TAG Privacy Task Force Call - 2 February 2022

Present: Dan, Jeffrey, Nick, Don, Pete, Robin


## Structure PR complete

the big PR (102) is merged! :tada:

## [Discuss appropriate use of data to prevent abuse.](https://github.com/w3ctag/privacy-principles/pull/105)

Nick: I have concerns about this PR... Risk that this could be an endorsement of the surveillance state.  So it doesn't sound balanced.

Christine: agree

Pete: make this less abstract & philosophical - up to other parts of the society to intervene - the privacy principles doc shouldn't say "let's not have too much privacy here"

Don: obligation to comply with the law - but should put the maximum amount of protection around what they have to do

Jeffrey: i don't think there are legal requirements to detect misinformation, but that is important for privacy

Robin: you could imagine where providing privacy requires collection data - so how to balance that. I'm unconformable with blessing corporate surveillance...   we need to support safety but give serious consideration to...

Christine: Does it need to be in this document?  I don't think we are putting elsewhere in the doc use cases that might violate privacy. If we put this use case in then are we going to talk about targeted or behavioral advertising?

Nick: we said: let's just talk about it in the sense it is supporting privacy - that one might be relevant even if others are out of scope.

Pete: if privacy goes in 2 different directions -- increasing overall privacy - the thing to do is not to write up how to adjudicate those but to document... and weigh in on the user's behalf. and involve the user when uncertain.

Jeffrey: in the cases where some users don't want a site to detect that they are trying to attack another user...

Pete: we should focus on what we know best - privacy on the web.

Dan: Reminder about 2014's [STRINT Workshop](https://www.w3.org/2014/strint/) -
STRINT workshop an example of the tech community coming together to respond to surveillance at scale on the Internet. this is contrary to the design goals of the Internet and a threat.
(pervasive monitoring is an attack)
we don't need to make it super easy for governments to surveil people on the web as they have other ways to detect criminality.

Jeffrey: we need to say something....

Robin: I'm aligned with the sentiment where we need to prevent surveillance - but there are legit use cases - society works by allowing in certain contexts - e.g. like a warrant - CCTV in a shop... we need to avoid validating where private companies are determining who's a terrorist... we need to push back - but we need to say something.  Discussion of legitimacy... we need to decide what's legitimate.  we could punt to other documents or considerations.

Christine: I hear you.  I want to be clear: this document is about setting privacy principles for the web. It should be consistent with the technical community position on pervasive monitoring.  I don't want to doc to say "it's ok if you're doing anti-abuse"  - I'm concerned about abuse but this is a privacy principles document.  Privacy by design prevents pervasive monitoring and other types of surveillance.

Don: Always the risk that some company can find a norms violation that they want to do  and then identify an abuse problem that could be addressed by doing it - and reverse engineer their justification.

Jeffrey: there's a whole ground between pervasive monitoring - a single company seeing IP addresses is not pervasive monitoring.  One of the reasons why private compamnies have built up anti-abuse teams is that public law enforcement is not active on the internet.

Nick: I've heard that justification a lot - but it's not my understanding - they seem to care a lot about online crime.

Dan: we could say it's out of scope.

Jeffrey: we could explicitly say we do not have consensus to make a recommendation.

Robin: maybe it's worth calling community attention to - pointing out something to the STRINT workshop - yes.   Have to agree with Jeffrey that law enforcement doesn't care about internet crime....

Christine: i would prefer we say it's out scope.  I feel that's the right answer.

Pete: i agree - also - feel slighly different to robin & jeffrey - losing legitimacy - i think the document will be taken less seriously.

Dan: also concern about legitimacy if not taking a strong position against surveillance

Jeffrey: a privacy right for children to only have conversation with other children... difficult situations - we want to ensure as much privacy as possible - but sometimes there needs to be a trade-off.

Nick: seems like a purpose specification designation...

Robin: i think it's worth calling it out in this context...

Tess: application of a purpose-specification principle, but not the only

## [principles for vulnerable people](https://github.com/w3ctag/privacy-principles/pull/114)

Robin: a number of changes from jeffrey...

Nick: seems like you're defining vulnerable as people who are easily coerced - but you can be vulnerable in lots of ways...

Christine: people might not be vulnerable normally but individuals at some point in time can be in a situation where they're particularly vulnerable.

Robin: there's a definition of v.p. which doesn't discuss coercion... to what Christine said - it can be engineered - that might be worth documenting as well.

Nick: the principle is phrased just for user agents - not sure that's what we want. Especially considering the contextual nature...

Jeffrey: actors should try to protect vulnerable people - applies to both UAs and sites.

Dan: referenced contextual UI flow in Webauthn

Jeffrey: belongs in another principle...

**mergey mc merge face**

## [EWP reference](https://github.com/w3ctag/privacy-principles/pull/116)

Christine: reading it, I'm wondering if we're weakening the value of the privacy principle - i know it shouldn't be taken as more or less important - let's say there are other documents that reference back... We could just say "it elaborates on the privacy principle" -

Jeffrey: i am worried that - people will think we are saying that "privacy trumps everything else" when in fact there are trade-offs.

Robin: would it address your concern if we drop "should not be taken as a statement." we just [keep it short].

Christine: I think that in some cases privacy does trump other things.

Nick: you have to consider it in the holistic sense - but we don't want to set it up as a fight between principles.

Jeffrey: I'm changing "when" to "if".

Dan: "privacy vs. x" is often a false dichotomy.

Don: privacy is often used as a way to justify controversial business practices and can turn into a general purpose excuse for doing things.

## Working Draft

Dan: are we happy to issue a first public working draft?

Christine: not against but not totally for

Nick: agree - a risk that people will think TAG doesn't care about topic x because that hasn't been settled yet.

Robin: let's take a week ...  Agree with Nick's point.  Let's take the week to go through this. Take a real solid fresh look at it.

[agreement to wait a week and gain feedback from the rest of the TAG in the meantime]

## "how to do it"?

Nick: techniques - do we want to cover it?  e.g. data minimisation.

Jeffrey: [link to](https://w3ctag.github.io/privacy-principles/#data-techniques) a section where we do discuss that.

Pete: i think the other stuff should be in another document.

Robin: what counts as a technique?  data minimisation as a general principle is a technique..  where do we want to draw that line.  It would be overstepping to have "this how you apply this complex system to data minimization"

Christine: top level principle and how it applies - and then fine-grained techniques in another document.

Nick: maybe high level strategies - some of that is in the questionnaire...
