# TAG Privacy TF Call Minutes - 20 July 2022

Present: Dan, Wendy, Christine, Nick, Shubhie, Don

## https://github.com/w3ctag/privacy-principles/pull/170

Dan: this [tag review](https://github.com/w3ctag/design-reviews/issues/739) for *Back/forward cache NotRestoredReasons API* - 
an example of site developers looking for performance telemetry, and it's a case where TAG would love to have established principles on telemetry to point to.

Nick: some people want browsers can have different heuristics -- some wanted "no, no heuristics are appropriate".  

Dan: look for wording that encourages browsers to seek user consent, but also enable
... has the user affirmatively agreed at some point (first use) to share telemetry with web sites?

Shubhie: treating all web sites equally.. we talked about... should there be an elevation of privilege - a gate with access to powerful capabilities after that.  e.g. bluetooth... powerful capabilities should be gated. Native apps have a natural places for that - installation. On the web we don't have such a thing. 2nd thing is user choice of not sharing.  Some browsers have private motes. We need to help the user in both directions.

..."thresholds" for different access/permissions

Nick: **to write text**

## https://github.com/w3ctag/privacy-principles/pull/173

Shubhie: supporting user choice - in 2 directions - in sign-in it starts to become that signal - elevation of privilege.  There might be other ones such as installing the app - should be a user's choice and browsers should suppor that. Should not be coerced - not consuming the content enough but being asked to sign in.  If the user is choosing not to share identity - it can be implicit or it can be using a private mode - that deserves protection.  Web sites blocking private modes can be another type of coercion.

Dan: related to [https://w3ctag.github.io/design-principles/#do-not-expose-use-of-private-browsing-mode]

Nick: for private mode we had a concern about how it's being deployed - we have a suggestioon that user agents shouldn't reveal it. what mitigations from user agents on coersive signin?

Shubhie: user agents ... auto-fill... sso. If there was a first class API 

Dan: such as FedCM...

Nick: it could be explicit - but what does the browser do? You can't hide from the web site whether the user is logged in...

Shubhie: it's more that the browser has an explicit insight .. signed in and signed out... But what power do we have over web sites?

Nick: do we want to have a principle about "web sites shouldn't do this" but if we have a UA guidelines then what would that be?

Shubhie: it would would be a elevation of privilege signal... if the user has signed out... first party cookies... partitioning... storage access... gets into tracking as well... IP address...

Don: don't know if it's just when the user does not *want* to present an identity.  Sometimes the site has a reason to require an identity.  If we're going to talk about not requiring an identity it should be about not requiring a user to present an identity in order to enable a site to do "bad things" 

Dan: need to account for first visits where you want to sign on, e.g. you just read about a new movie service and know you want to join

Don: sites that just give you the summary and then require login to get the full info / article. A lot of users are used to this practice - it's common enough going back to the days of business reply mail postcards (and a long history of a business practice is imho a good sign that it's widely accepted)

Dan: ...marginalised communties...

Nick: maybe it's fine to give that guidance to web sites... we can give some reasons.  Valuable to have the web experience - something useful if logged out.  More than a sign-up form.  Analogue is that we think user agents should help users present different accounts and help them protect their identities...  such as *anonymous remailers*...   

https://relay.firefox.com/
https://duckduckgo.com/email/faq


Don: we already cover something relevant - cross-context recognition. Just because you fill in your info to get info on one thing don't correlate to another thing. A user reflects different identities in different contexts.(b2b purchasing responsibilities are separate from family health care) Respnsibility of the site not to use info for cross-context recognition. "sites can ask the user for info relevant to context that they're in - but if you try to take that info and connect it outside the scope of what the user would choose to share then that's outside the principles."

Shubhie: i think the private email discussion... presenting choice... missing... also notion of what are you actually agree to when you sign up or sign in.  users don't understand that... maybe some text. 

Dan: [fedcm](https://github.com/w3ctag/design-reviews/issues/718)

### 2 announcements about fb encrypting tracking paremeters - and a research paper on timing attacks

Nick: timing attacks: web site opens another window to see if the user is logged in and find account identifier for other web sites.  Should either be addressed explicitly in privacy principles...  Maybe just in privacy IG call and come back with a recommendation..

https://www.ghacks.net/2022/07/17/facebook-has-started-to-encrypt-links-to-counter-privacy-improving-url-stripping/



Wendy: useful addition to a collection (elsewhere) of examples of 2nd order privacy effects... ecossytem reactions to initial moves to protect privacy have rebound reactions.

Nick:  the paremeters one we expected but didn't expect it so quickly

https://www.wired.com/story/web-deanonymization-side-channel-attack-njit/

Nick: timing attacks to see if you can find the user's email address... 
