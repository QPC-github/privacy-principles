# TAG Privacy TF Minutes  - Wed, 1 December 2021

Present: Dan, Wendy, Robin, Jeffrey, Pete, Tess, Don
Regrets: Amy, Christine

## Agenda

[Remove the Vegas Rule](https://github.com/w3ctag/privacy-principles/pull/77)

Jeffrey: suggested removing this as we don't use it in the document. not necessary or sufficient for data use to be appropriate -- 

Robin: plenty of cases where it's sufficient or necessary. we could discuss exceptions. it would help to have concrete ... want to figure out what exception.. if it's fraud prevention then let's make an exception. I've found this is a good way to get peoples attention ... something that can be referenced as a short hand ...  It helps to have better communication tools...

Jeffrey: i think it's plausable to keep it - i don't like the claim that it's necessary... As we dig into it more in the computer world it's not required... 

Robin: we could convey it as a typical way of thinking about it... something that reflects the fact that it's reflexive of real world... 

Jeffrey: it's helpful - it's a helpful guideline - it could be a best practice.

Robin: I like best practice...

Don: two basic kinds of fraud protection: where the intended victim of the fraud is the user; where the intended victim is some other party. From a priority of const. pov it seems protecting the user from fraud is more important.

Jeffrey: lot of users...

Don: if one user is trying to break into the account of another user then it's fraud with a user as victim even if it's not the user in that session.

Jeffrey: the exception for a case you might want to violate this rule - a user is running sock puppet accounts - so you share info about them with 3rd parties to block them across multiple sites.

Robin: yes - another discussion is worth having around privacy violations that are legal in nature.. 

Jeffrey: it's a case where the vegas rule isn't necessary.

Robin: in an ideal world the vegas rule would have specific exceptions...  Happy to take Jeffrey's PR and turn it into a best practice... 

Jeffrey: I'll revert that deletion now...

Robin: I will take another pass and turn it into a best practice.

**merged as is**

[Allow UA behavior that only indirectly benefits the user.](https://github.com/w3ctag/privacy-principles/pull/78)

Robin: I think that's fine [removing "directly"] - though I have suspicion for indirect benefits. In this case it's OK.

Dan: Suggest we merge.

**merged**

Jeffrey: plausably more stuff to add about which indirect benefits are ok.

Robin: I will think about it.  

[Say that careful cross-context data sharing can be appropriate.](https://github.com/w3ctag/privacy-principles/pull/80)

Robin: problem with the definition of context... it describes context as having a single purpose. I think context has sets of purposes.  In a shop there's a commercial context there are other contexts... If you have just one context ... it may be appropriate for a 3rd party to market to users of a bank for example in some cases.

Don: if you have a user population that's highly aware of how data may be used by partner companies or teams in the same company then .. is the user understanding of those practices important..?

Robin: i think it's about norms within that context.  e.g. if your doctor used info about you to advertise for a non-medical product then it's inappropriate.  But it might not be a violation of privacy... 

Jeffrey: narrow interpretation ... only inapproriate data sharing. also privacy violations about intrusiveness ... even if the doctor hasn't shared data then it's still a privacy violation...

Robin: I agree but i don't think the data processing is the issue - the issue arises if they use medical facts about you to target you...  sucks but not sure it's a privacy violation?

Jeffrey: this may be key to the concept of same party contexts... a same person might have multiple contexts inside of them - they are your doctor but also a person... 

Tess: same 

Jeffrey: maybe merge and we can improve the example.

**merged**

[Reorder the definition of "personal data".](https://github.com/w3ctag/privacy-principles/pull/88)

**agreed to merge**

[Organize the document coherently](https://github.com/w3ctag/privacy-principles/issues/89)

Robin: worth thinking about the structure before we do the PR because it's gonna be a big PR. .. the one thing that gives me pause - i wonder if we aren't jumping into the habbits for standards people talking to standards people... all the definitions first etc... Give people a sense of the ethics first...

Dan: I think we should aim for having a friendly, human-readable document.

Jeffrey: should we get a tech writer?

Jeffrey: we could move some of the definitions down into the ethical data use...

Robin: I wonder if the problem is that we're calling it definitions...   Here the definitions are meaningful in a way where people read them before jumping into ...

Tess: key concepts...

Robin: we need more discussion in the definitions...  e.g. "privacy involves people and when we talk about people we need to define what we mean by people..." 

Jeffrey: we could move the less surprising definition into the glossary at the back...

Dan: i could write some of that extra text...  

Robin: if we want to make every section flow properly before we re-arrange. if we re-arrange first we can convince ourselves it's the right structure...

Jeffrey: i like the idea of rearranging first.  I also want to get Christine's opinion on this structure.

Tess: [on glossaries] - the point of the document is providing these definitions so having it early might be better.  Maybe another way to break it into multiple sections - "how boring the definition is".  Person definition might need to go at the end.  Other ones are kind of vital to read in-line as you're going... Not as easy as a rule, but.. might improve readability.

Robin: not so much a glossary - more of a common concepts.   and make that an appendix.

Tess: yes.

**agreement to work on this**

[Include origin sovereignty](https://github.com/w3ctag/privacy-principles/issues/79)

Robin: agree with the feedback - suggest I spend some weeks thinking about it.. if i agree with the pushback may close it. if i disagree will make PR.

## Schedule

Dan: next call on the 15th.

Don: I will be out but will review PRs before hand

Dan: when to issue a public wd?

Robin: not before the reorg of the doc issue is resolved...  We should agree a level at which we can issue a fpwd... If the document is organised coherently and there's no contentious issue then I'm fine doing it.

Jeffrey: Yes once it's reorganised I'm happy.

Robin: we re-organise between now and January...

Wendy: we should all of us be comfortable to defend the shape. 

## [Should we have a section on authorised agents?](https://github.com/w3ctag/privacy-principles/issues/81)

Don: an authorised agent is an intermediary that is not the user agent... in CCPA your authorized agent can do privacy labor for you... Organise and automate privacy labor. Auth agents do privacy labor including some work that by the standards of the rest of the doc they should not have to do but in real world jurisdictions you have an overlap between personal data processed in a web context and p.d. that is processed in an offline context.  If you buy a coffee from a machine and it face recognizes you and ties it to your social profile - then it's collected outside the web but used where there's an opportunity to influence how that data is processed. Global privacy control is a complement to authorized agents. GPC is in your HTTP session and it can pass over to anyone you have that connection in software. But other parties that the user has the legal right to influence are not in the HTTP session, so an authorized agent can touch them when GPC can't.

Dan: e.g. could Blockparty could be an auth agent?

Don: a CCPA auth agent does that with specific things you're allowed to do in one US state. Blockparty does actions according to the API of a particular party, moderation labour. Related to privacy, but moderation and privacy labor aren't the same even though similar and often affect data handling by the same parties (example: a social site that does both moderated content and ad targeting)

Robin: a good example - some discussions taking place in Europe that have tools which could withdrawl consent for you asynchronously .. would know your online behaviour and automatically send a message to withdrawl consent to sites you don't visit.  

Don: With an authorized agent service, you sign a permission letter to authorize a service to act on your privacy norms and preferences in a certain jurisdiction... The service gets to take the user's general norms and preferences and then map them to what's technically possible and legally possible.

Robin: another classic example - authorising someone to do something with your data after your death. You don't want your chat logs to go to your family for example... 

Dan: what should be in the document?

Don: to be specific I'm only knowledgeable about authorized ageents in california...

Jeffrey: i'd like to know what principle we should have.  e.g. services should make it possible to delegate their privacy labour to authorized.  user agents should make it possible to install authorized agents.

Don: the maintainer of an ad blocker filter list would be a trusted intermediary. The user doesn't expect that the maintainer of an ad blocker filter list would subvert that list according to their own business model. The gray area is the browser extension.  When the browser allows the user to install the extention - is that extension code bound to the same duties to the user that the browser is? That would imply that the filter list maintainer is also in that trusted intermediary space, with responsibility to the user.  user -> ad blocker -> filter list...

Jeffrey: in practice browsers don't check that extensions behave as well as the browser would.  We could say that extension authors do have obligations to end users...

