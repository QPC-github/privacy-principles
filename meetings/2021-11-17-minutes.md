# TAG Privacy TF - Wed, 17 November 2021

Present: Dan, Don, Jeffrey, Amy, Pete, Robin, Jonathan, Wendy, Christine, Sam

## Minutes

### [People & Data style improvements](https://github.com/w3ctag/privacy-principles/pull/30)

Jeffrey: about personal data definition. Robin's current text is very close ot some of the regulatory definitions but it differs in a couple of ways. I suggested differing it in other ways. I think we should cite the regulations... relating to a person, is that different from 'about'?

Robin: 'about' is clearer, normal language

Christine: [in chat] +1

Robin: will also add a citation

Jeffrey: directly or indirectly, not sure it's correct ... what we mean by it?

Robin: checking GDPR

Christine: also seen definitions talk about indirect or direct, a lot of variation

Jeffrey: indirect worries me a bit, because some factsa bout the world are related to me indirectly, I dont think we want to include those in definitions of personal data

Christine: direct is too confined

Robin: GDPR uses it

Jeffrey: directly or indirectly includes everything... worried too much?

Robin: reason it was included initially was because without including it some lawyers will make the case that only direct identification matters. If I know your entire geolocation I have identified you but it's indirect. That's what it's trying to catch. There's probably a tapering off, where something can be very remotely ... I think we need it, but I heard your point that maybe there needs to be something in there that limits the indirectly. Everything is related...

Jeffrey: we can come back to it if it becomes a problem

Dan: reasonable to .. always going to be some ambiguity. Keep it.

Jeffrey: another peice of that comment.. 

Robin: copied almost verbatim from GDPR. Happy to turn 'in particular' into 'such as'. They are trying to draw focus on usage that does that, so we are specifically worried about this, not that others aren't important. 

Dan: "data is personal if..."

Jeffrey: you didn't write "only if" but a lot of people read "if" that way

Robin: looks good to me

Christine: one crucial difference is I've added identified in my suggested text, both, identified or reidentified

Re https://github.com/w3ctag/privacy-principles/pull/30#discussion_r750623738

Robin: Think about FLOC, where you get a cohort ID that doesn't identify or single out a particular person, but does say this person is part of a group.

Don: It's differently actionable for different parties. One group might hold information about a person beyond just the cohort identifiers. If a company has more information, the cohort ID might be more information. A site with low traffic might not be able to draw inferences from a cohort when a site with many logged-in users can. Cohort ID behaves differently depending on who's checking it.

Robin: See what Jeffrey's saying about this being too broad. Like get some geolocation "I know you're in France", which is a group. Maybe we move this out of the personal data considerations into a new "considerations for cohorts" section where we could go into more detail.

Jonathan: Is the cohort size the important thing?

Robin: Not just that. 10k people who happen to be Black or women or overindexed on those traits, there are lots of problematic behaviors that are data-grounded that we should be in a position to say something about. That data needs some data protection.

Don: This isn't just explicit cohorts. An emergent cohort: language A in region B.

Robin: 

Jeffrey: part of this might get resolved by it being de-identified data.. if you attach your cohort to an indivudual then it's no longer anonomyzed... it's all about aggregation... turning user data into business data - controlls on it are less strict because it's about a user base.

Robin: comfortable removing it and adding an issue on cohorts... so happens that in this juncture in timne... in terms of data protection controls don't need to be as severe.

J: Seprarate example - my site's user data can tell specific data that is used to target ads to that kind of person - do we want to say something about how ads are targeted in this way.

Robin: yes i think we don't want to call that personal data... it's contextual... contextual data can also be used to discriminate.

Wendy: that raises the challenge of scope - a lot of the issues we may be addressing intersect with privacy issues but are also bigger - we may want to recognize some of these as something to note for more docs....

Robin: very privacy related - but in the case of cohorts there are these considerations... 

Don: the advertiser/publisher web is not the only web. Also a website that could be the portal you log into as a tenant to manage your relationship with a property management company. All of this stuff has to be relevant for subscription based services, content creation, all other categories, not just advertiser/publisher intermediary case

Dan: Voicing support for a category of issues of things we might set aside. Amy is working on a document on societal impacts, which that might fit into.

Robin: Lot of work there.

Jeffrey: Whole section on impacts on groups that maybe should move to Amy's document.

-----

Christine: There's no such thing as "permanently", or it's very rare.

Jeffrey: Suggested "anonymized" because Google uses it internally, but don't feel strongly.

Christine: Prefer "de-identified". "Anonymous" gives the impression of anonymity. "De-identified" doesn't go that far.

Jeffrey: Fine with me.

Christine: We also talk about "pseudonymous data". Call that "Controlled de-identified data". The definition is that it's de-identified via a protection with strict legal controls.

Wendy: Christine's suggestion addresses "pseudonymous w.r.t whom"

Christine: If you reallyi want to keep "pseudonymous data", could say that identifiers have been replaced with data that's not strictly identifying.

Robin: I like your label better, and happy it addresses Wendy's question too. Pushing gently back on omitting "pseudonymous" because people use that a lot. Would rather anchor that to something we like that's somewhat strict. Right now, it covers all sorts of things. We could say "Controlled de-identified data is often referred to as pseudonymous data."

Christine: See the point and agree with the reasoning about why it's useful. I think there's a difference between the first definition, where there are strict controls, whereas most people think "I haven't logged in as Christine; I logged in as Cow." which doesn't have strict controls.

Robin: See what you mean. There's 2 senses. Individual might use a pseudonymous identity on social media or comments, and there's what people trade as "pseudonymous" or "pseudo-anonymous". Not sure which to pick. Will noodle on this. Will change to "controlled de-identified" and open a separate issue on how and whether to define pseudonymous.

[...processing suggested changes]

Robin will make the agreed changes and commit.

### [Remove the Vegas Rule](https://github.com/w3ctag/privacy-principles/pull/77)

### [Allow UA behavior that only indirectly benefits the user.](https://github.com/w3ctag/privacy-principles/pull/78)

### [Say that careful cross-context data sharing can be appropriate.](https://github.com/w3ctag/privacy-principles/pull/80)

Christine: not just context, dosn't there also need to be legitimate purpose?

Jeffrey: difference with contextual integrity.. legitimate purpose is the legal .. but not used in this section

Christine: see what you're saying, not excluding other requirements. Leave it as it is

Don: is kind of abstract, might help to have some kind of example. People might read too much into it (or too little)

Jeffrey: the example there might e too abstract

Dan: capture it as an issue and land the PR?

Christine: example of different contexts I use are information you shared with your bank for the puprose of doing banking, and the bank shared it with other parties for the purpose of advertising, it's a different context that you never anticipated

Dan: better as something real

Don: if your avatar in a game has a jacket and you go to a retailer that sponsors that game can they offer you the same jacket even though it's a physical context vs a gaming context

Jeffrey: real world example... you go to a therapist and you meet them at a cocktail party and theyr'e required to not recognise you at a cocktail party.. but they know you're triggered by discussion of husbands so avoid that topic of conversation at the cocktail party... shared data across contexts.. or should we restrict to computer uses?

Robin: one thing to use that information but not share it in another context.. another thing if a therapy chat bot learns your trigger then the CEO of that company avoids the topic at a cocktail party

Dan: I think banking is the best ne..

Don: norms are not to share that information in customer banking relationship

Jeffrey: will rewrite, would like to run the next text by Robin

### Making it clear in the document status this is headed for W3C Statement

### Should we issue a working draft?


