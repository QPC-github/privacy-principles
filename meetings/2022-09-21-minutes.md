# TAG Privacy TF Call - Wed, 21 September 2022

Present: Don, Jeffrey, Christine, Dan, Sam, Tess, Nick, Pete, Wendy
Regrets: Amy, Robin

## Some discussion on TPAC

## [Try to explain how new APIs can or can't be justified based on old ones](https://github.com/w3ctag/privacy-principles/pull/182)

Jeffrey: came out of some discussion at TPAC ... might be more appropriate for design principles or something else. .. 

Nick: very important thing that comes up in privacy work.

Dan: we have something similar in https://w3ctag.github.io/design-principles/#leave-the-web-better design principles

Tess: we should cross-link these things. Links are good.

Sam: I think it's incomplete. 

Jeffrey: I said in the 2nd subsection... 

Tess: 3rd subsection might also need further wording...

Jeffrey: if we have no plan ... and implausable to remove the bad thing... doesn't make sense to slow other things down..

Tess: suppose you have an existing thing that's terrible... chance in the future that we might resposibly remove it but currently can't.  if people add duplicate functionality elsewhere then in the future we have a bigger problem.

Nick: I do think the "we have a plan" condition is not what I'm looking for. Puts a lot of burden...  Sometimes we don't have a plan and then we do.  UA String is a good example - people felt we couldn't do anything... In the past few years we're making more progress.. If things are competely identical... adding it somewhere else ... often my quesiton is "why do you need it?"  Certain amount of question of "which things are actually identical"?

Don: concrete examples?  Recent example of bounce tracking mitigations is constructive.  General sense that bounce tracking would be mitigated... we expected that browsers will test their mitigations against deployed bounce tracking solutions... that discouraged sites from investgating bounce tracking and browsers didn't have to write code... so: if a current practice is unaccepable then future methods will also be unacceptable...

Sam: do you include in that "unacceptable but currently in use"?

Don: Bounce tracking was positioned as a solution to cookies going away...but talk of mitigations prevented it (the existence of the capacity to push a fix helped protect users by discouraging investmeent in bounce tracking)

Pete: if it's available in some cases... if one browser wants to disable a certain thing... changes the math of browsers willing to break sites for privacy reasons...

Nick: +1. even if you think all browsers implement x that might not be the case.

Jeffrey: we should say "some browsers have more appetite for breaking some sites, and new features need to not make things worse for them"


Dan: Geolocation was written before we moved the web to HTTPS, and then it was changed to be only active under HTTPS. We could have had APIs for other sensors that said "geolocation doesn't need to be secure, so why do we?" We avoided that well.

Jeffrey: it falls under "we have a plan to improve things"

Dan: depends on the definition of "we" and "plan".

Jeffrey: we can keep it fuzzy...

Nick: I think we should have examples...

dan: maybe having an example would be a good idea...

Jeffrey: one is in there... Scroll position based on JS is another example... Trying to block intersection observer because we want to block scroll position... some would argue that io is OK.

Nick: I think "clicking a link" is the kind of contentious example I'm thinking of... that seems like an area where interventions are possible... link shorteners... disable JS click handlers.... etc...

Jeffrey: argument on the ping attribute is that it makes this easier...  Economic argument - we shouldn't make bad information cheaper... 

**general support for having this**

Don: cautiously optimistic about the ability of browsers to deploy mitigations to discourage disinvesting in problematic tracking practices (even before they actually write code).

Sam: something but need changes...

Jeffrey: I'll also do another pass.

Dan: I'll take a look at it for style as well.

## https://github.com/w3ctag/privacy-principles/pull/170

Nick: interesting meetings at TPAC about performance and ancilary uses... I think the right thing is to split up the PR... on the anlytics/telemetry thing we're on the right track.  One thing we should have feedback on: fingerprintabilty if people turn off telemetry... Reveals you're in private browsing mode ...

Dan: only if it's ubiquitously turned on elsewhere...

Nick: if people followed out suggestion ot ask the user then it would be revealing the user's choice...

Jeffrey: setting the option is likely to be a fingerprinting bit... fine for the browser on the whole to turn it on or off... we might want to think of browsers as whole...

Dan: can't you mitigate by sending false telemetry?

Jeffrey: It's hard to mask, because a browser can do something it knows would send telemetry, and check; or you can coin-flip, but then sites will likely work-around

Pete: that concern seems less than that if telemetry is enabled

Jeffrey: network info is more controversial; less is CSP reports, deprecation reports, element timing. stuff that's already there but makes it easier for sites to gather site data

Pete: even timing info is more identifying than single bit

Jeffrey: new APIs collate information, but only info that's already there

Pete: the pattern, fact that there's info elsewhere doesn't change the value of a bit @@

Dan: we want to level up privacy for everyone. Looking at settngs with ability to opt out of telemetry short of choosing a different browser

Jeffrey: general point, adding a setting has a privacy cost. It has to pay for itself

Don: ties into rights of device owners. If you're an IT dept with a cluster of users who'd be telemetry-identified, owner of devices could deploy a privacy profile. 

Tess: web in general has higher baseline of privacy than other platforms, but that's a floor. Still good that browsers compete on top. Make the target baseline sufficiently private to fulfil web promise. 

Jeffrey: any time we say there should be an option, we're not raising baseline

Nick: Privacy is not uniform, so don't agree re options.

Jeffrey: good point

Nick: I'm going to split my PR. Capabilities, choices, analytics mode might be positive direction. 

Dan: any other TPAC discussions? 

Nick: privacy attestation... requiring a promise that data only used for a specific context e.g. ... Also labeling type info... to see how their websites are acting..

Sam: devices & sensors... where they didn't see good enough documentation... Not enough guidance on how to count bits of entropy, how to count ephemeral fingerprinting... also was where do we document that we want to return the same error if the sensor isn't there vs if the request is denied.

... also - anti-fraud CG... they want to track abuse.  Seems to me they need to do more due dilligence on publishers ... rather than rely on holes to poke throuh..

... token binding in IETF... 

Jeffrey: that was the idea to bind cookies to device?   

Don: on anti-fraud we need to be realistic on filtering fraudulant sites... there are ad tech biz models that work better with portion of fraudulant sites in the system. Can't expect to get every player in the system to agree to excluding certain kinds of sites. Multiple layers of protection will be needed. 3rd party can be assumed to be adversarial to the user in many cases (attempting to monetize low-quality or deceptive sites)

Dan: [we have some detail in the design principles](https://w3ctag.github.io/design-principles/#device-apis) on devices but maybe not clear enough...

Dan: I addded a [design principles issue](https://github.com/w3ctag/design-principles/issues/398)

