# TAG Privacy TF Call - Wed, 23 February 2022

Present: Dan, Nick, Don, Pete, Wendy, Sam, Tess, Christine
Regrets: Robin, Jeffrey

Fewer folks today, may have a shorter conversation.

## [pr 133](https://github.com/w3ctag/privacy-principles/pull/133)

Pete: effort to simpligy personal data section - and restructure this to an enumeration of specific principles.

Dan: move the definitions into section 1?

[general agreement to do that]

Dan: make more actionable principles for section 2: what should someone do based on this; active voice; normative statements

Pete to modify PR to move definitions to previous section as well as those changes

## [pr 136](https://github.com/w3ctag/privacy-principles/pull/136)

[discussion on automated decision making and whether we should include some speicifc examples]

Nick: ...opting out of profiling...

Tess: I have an email provider - with automated spam filtering.. and there's a risk with misclassification that I might miss some important info. Missing that could impact my credit rating.. but we don't mean "email providers shouldn't provide automanted spam filtering"

Nick: no - more making decisions based on data about me...

Tess: in some cases it does use info about you...

Don: Spam filters - in order to be effective they need to be not disclosed - to make them less gameable...

Nick: i think the motivation for the laws - - if you're making a judgement about me - e.g. drawing inferences based on an algorithm's decision about the person - I should be able to object. Credit worthiness, etc...

Nick: comes up in advertising contexts - making offers to people based on some data about them... potentially impactful decision.  

Tess: **price discrimination** based on what device you have https://www.bbc.com/news/technology-18595347

Christine: an office supply store changed price based on your location... https://venturebeat.com/2012/12/24/staples-online-stores-price-changes/

Dan: too far towards the world vs. on the web?

Pete: not just bad because thee are under rights....

Nick: in some legal contexts they described it as a person's right.

Dan: what principles can we draw out?

Nick: if we have data on a system or access data about ones-self - would need to implement things like "see this data about you" or "deletion request" - principles like new features developed collaboratively.

Don: related - discussion came up in FLoC. [Is this thing revelant to dynamic pricing](https://github.com/WICG/floc/issues/105) ? FLoC no longer being discussed but [I filed an issue](https://github.com/jkarlin/topics/issues/34) on Topics API which is related. 

[discussion on price discrimination]

Don: Price discrimination can be considered as a harm to the user, related principle is **sharing info about a person in a way that's not clear to that person.**

Dan: it has something to do with primary use / secondary use as well...

Pete: we have that ...

Nick: how about: **parties and user agents should provide access and ability to delete data stored about them on client and server.**

Dan: if a feature (like Topics API) makes inferences and stores data on the user agent perspective, users should be able to inspect/audit and delete

Sam: automated decisions vs non-automated decisions - both can be harmful.

Nick: saying there's a right to be free from automated decision making is not saying that's the only way to implement privacy, just providing some after-the-fact data rights (in addition to controls about collection, etc.)


[pR 132 ](https://github.com/w3ctag/privacy-principles/pull/132)

Nick: example of pop-up blockers - implemented by all browsers - as an example of something browsers needed to do to fix the problem of intrusive use of a web technology

are there references on the history and motivations of pop-up blocking as a collectively-developed browser feature to protect against intrusion?
