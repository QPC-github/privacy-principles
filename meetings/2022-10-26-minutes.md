# TAG Privacy Task Force - 26 October 2022

Present: Christine, Jeffrey, Don, Sam, Nick, Amy, Wendy, Pete

Regrets: Dan

## [PR: Editorial pass on Identity principle](https://github.com/w3ctag/privacy-principles/pull/177)

Amy: all feedback covered except one issue raised. [Discussion about timing attacks](https://github.com/w3ctag/privacy-principles/pull/177#discussion_r957647129) I wasn't sure about.

Jeffrey: Can't find it, file a bug

[merged]

## [PR: describe cross-device communication, with cited silverpush example #186](https://github.com/w3ctag/privacy-principles/pull/186)

Don: looks good to me

Nick: shouldn't be complicated. Idea is to talk about definition of partitian.. implies you shouldn't be able to connect users on different browsers or across different devices, but this is explicitly about idfferent devices being a different way to accomplish cross partition recognition, and citing ultra sonic light signals to communicate between devices. I can fix conflicts.

Nick to fix conflicts and merge.

## [PR: Try to explain how new APIs can or can't be justified based on old ones. #182](https://github.com/w3ctag/privacy-principles/pull/182)

Jeffrey doesn't yet have an update on this. Will do so for next week.

Sam: I don't have wording to suggest.

Christine: An example could be, when we were moving APIs to HTTPS, geolocation people initially said it's deployed, and you'll break everything; we won't do it yet. Example of sending data over unencrypted channel doesn't mean others can do it.

## [PR: deception](https://github.com/w3ctag/privacy-principles/pull/181)

Nick did a revision with suggested chagnes. Prefer to talk about "not asserting truths" so we don't have to talk about deception.

Jeffrey: not sure we can avoid contention, given the push for actual attestation APIs. Focussing on trying not to assert truths and just asserting the uesrs opinion is a good place to start.

Nick: I'm open to there being some rare cases where an API has to include an attestation. We might need to support deception in that case. I was trying to change it partly to say - and I think Robin already had something about this - when a site is doing threat modelling they should assume the things they get from the UA are under the control of the user so you shouldn't have high confidence in that signal if you think the user might want to be lying to you, because they can. I am hoping this could be a principle that will help us when eg. in some of the anti-fraud group discussions. What if a browser just gave us a guarantee about how old a cookie is and the browser didn't let the user clear cookies or delete something or something like that. I'm happy to make tha tpoint, but I think it would be useful to right this down. Preventing users from controlling their own software is not a very promising anti fraud technique.

Don: the browser is doing what the user would do if they had the time.

Nick: the suggestion is just we should have the browser do something the user doesn't want to do -...

Don: that would be a job for another kind of software other than a browser. The browser is the agent of the user completely

Nick: that's the contention - I don't think there's universal agreement on that. 

Don: precedent in EME for there to be the foreign consulate of some other party on the user's territory but that's a special case and a special piece of software that is not the browser.

Nick: if anyone wants to look at revisions or has other suggestions that would be a good one to merge. Even if it can't be completely free of contention it can be a little easier.

Amy: a couple of outstanding suggested changes

Jeffrey: [merges those]

Nick: will make a new PR on that branch with suggested edits

## Issues

Nick: does everyone have issues to work on?

Don: I don't, can take a high priority issue to write. [#172](https://github.com/w3ctag/privacy-principles/issues/172)?

Jeffrey: if you want to take that, go ahead.

### [purpose specific APIs](https://github.com/w3ctag/privacy-principles/issues/175)

Christine: any ideas what to write for this?

Nick: this is tricky, can work on it. Not sure we have anything like this so will be new.

Amy: We've talked about this relating to 3p cookies replacement APIs - FedCM is a good example of not doing a general thing to replace a specific funciton. FPS was not. There's a design principle about the opposite of this too.

Christine: if we design something specific for a very specific purpose.. but then people will figure out a way to use it for a different purpose.. perhaps an example is when WebRTC was leaking local IP addresses, a major publication seemed to be implementing WebRTC for a purpose that was unclear. It's a thing we've faced a lot in PING. Examples are WoT and Web Payments, where I think a lot of the push back has been don't worry, this is only for this every specific use and we've got other safeguards. But the problem is the technology potentially could be used in unanticipated ways. What are we going to say about that.

Sam: you might be thinking about the anti fraud people and how that relates to payments

Jeffrey: payment handler can be a general third party top level frame with unlimited communication with the invoking page. I know our payments people have pointed out it can't be fully except from the partitioning changes becuase it can be abused. I think Christine's point is that when we have a purpose limited API it actually has to be technically limited to that purpose. The space also interacts with an argument I've had on th FUGU apis where it would be ncie to provid ea really generic low level API, as the advice of the design principle,and that has to be limited by our ability to explain it to users and what we're telling users is comphrehensible and actually the limitation of the api. It would be nice to give web pages access to make arbitrary tcp connections but we can't explain that to users so we build things like web sockets and technically limited apis. This principle would be a good place to elaborate on that.

Nick: [Design principle](https://www.w3.org/TR/design-principles/#high-level-low-level) is more vague than I'd expect. 

Jeffrey: Extensible web manifesto is the most do it low level argument 

Nick: should we just cite the design principle? And is high level vs low level right? Or is general purpose vs specific better?

Jeffrey: specific vs general might be more precise and a better term - could update the design principle.

Nick: we could write it's good for privacy for apis to be purpose specific in this way, and refer to the design principle and we're elaborating a little bit.

Amy: I can write

### [rights of children](https://github.com/w3ctag/privacy-principles/issues/157)

Jeffrey: can someone take this?

Nick: don't we have a section on vulnerable people? Empty section

Don: some early definitions about vulnerable people

Christine: I'm happy to look at this. I'd make a point - even people who are not categorised as vulnerable can be vulnerable from a privacy perspective if put in a given context. Send examples my way.

Nick: I had looped in Tess... We should not have these sections empty when we finish the document. Opened issue for empty sections.

Sam: there's an inline issue about users paying for use in data, do we have an issue that says we should write that? [#120](https://github.com/w3ctag/privacy-principles/issues/120) is related. [files issue]

### Consider closing issues

#### [data minimisation](https://github.com/w3ctag/privacy-principles/issues/23)

Nick: we merged a PR.

Jeffrey: good enough to close the issue

Don: makes sense

#### [aggregate statistics](https://github.com/w3ctag/privacy-principles/issues/121]

Jeffrey: ancilliary uses covers this, we can close

#### [Privacy rules overrideen](https://github.com/w3ctag/privacy-principles/issues/137)

Nick: we merged something from Jeffrey, addressed?

Jeffrey: correct

#### [distingushing non-sensitive..](https://github.com/w3ctag/privacy-principles/issues/159)

Nick: I opened this.. Merged a PR, and data minimisation also includes text to say minimise generally not just certain categories. I think last week Dan added consider closing but wanted to wait for Pete.

#### [additional threats from unknown parties](https://github.com/w3ctag/privacy-principles/issues/161)

Nick: I opened this about increased threat model. Text was merged about parties that have access to the network and pervasive monitoring as an attack. That would be enough to close this issue, but we don't have an exhaustive list of those types of threats. I'd be fine closing this, but i fsomeone wants to keep it open and write up more I'm open to that.

Jeffrey: unlikely to get new text, not worth keeping open

Don: I think the text in PR 185 covers it well.. listing every party who wants to do bad things on thei internet would make the document too long.

## [Permissions workshop](https://www.w3.org/Privacy/permissions-ws-2022/)

Nick: applied to attend remotely. Maybe good to take outputs of that to see if there's anything we need to add to the principles. We dont' have much about permissions.

Nick: guidance after last workshop was some questions about adding another permission, and that is the kind of content I would like to integrate: https://github.com/w3cping/adding-permissions

Jeffrey: related to consent

Christine: we definitely enounter 'its okay becuase we ask permission' a lot

Don: we encounter conflict between what in principle is the right thing to do and what real world websites will have to do for legal purposes. According to privacy principles it's bad to put privacy labour on people. But according to certain countries laws you need to get 'consent' for. So the problem is you need to get consent to do a certain thing under GDPR because that's the only basis for processing that applies but then making th euser do that privayc labour is against privacy principles. So you've got this conflict where if you want to do something like a super deluxe mathematical attribution system you want to make the math hard enough that you don't need to get consent for it but you have to get consent for it anyway, so now you're trying to get consent for a thing you can't get consent for. So that implies that certain kinds of data procssing can't happen at all... I'm trying to fiure out what you do when you're required to get consent but consent is not the right thing to do.

Nick: I do think we have reasonable text in there on consent that is maybe helpful for that. Botht hat we should minimise the labour and also that if you are going to have an opt out model which we think is apropriate in some cases this is how it should work.. global, not case by case.. agent should be able to handel that for you.. so I think maybe we're giving reasonable guidence there. I don't actually know if the GDPR would insist that consent would be only justification for that type of processing.

Don: it's nto the only basis for processing, but people are talking about using it to feed into cross context behavioural advertising. As soon as you're doing that you're limitied in what basis for processing you can use. I do'nt like the idea of telling everyone that you should make things that don't require getting consent because of the problems of running this through a legal meeting. I want the document to be relevant to real world projects and if we get too far away from what people feel is safe ground especially GDPR wise then we end up being less useful.

Jeffrey: I think Adrian's diagram is useful for consent, not just permissions. The stuff where automatic grant, revertability and severity being good, are probably also cases where you oculd use another legal basis. It wouldn't be possible ot cause enough harm with the data that it would need consent, and then a higher levels do talk about getting consent or having the user pick which is another way of getting consent. So I think the guidence is don't ask for consent if you don't need it. And ask for consent in good ways if you do need it. And don't do stupid cookie dialogs unless you're legally required to. There are things you're legally required to do that don't make sense, like ask for all local sotrage, and you have to do them anyway, but those are not privacy issues. WE wouldn't say don't show this bad dialog that you'r eshowing for legal reasons. We would say try not to use data in ways that make you show extra dialogs. 

Don: unfortunately in the real worl dw'eve got fair consent, sneaky consent and don't ask for consent. THe lawyers will tell you in some cases you can do sneaky consent. if the privacy principles say no consent, we can't really say we don't think this processing needs consent according to our principles, so go do sneaky consent.. should be real consent or no consent, even if your lawyer would let you get away with sneaky consent. 

Jeffrey: should we say that? if the user is tricked into clicking consent for something that is not actually a problem, are we unahppy with that situation?

Don: if you let sites get away with sneaky consent where you don't think consent is needed, then users get acclimated to sneaky consent and then they might give consent where fair consent is appropriate but the site tried to get away with sneaky consent.

Jeffrey: I think we'd say the site should do fair consent when they have a privacy issue. Separate those two flows. Users will see two different fows and not have been acclimated. Obviosly we can't prevent sites form doing sneaky consent where there is a privacy issue, soem are going to do that. But use consent methods that respect the users agency when there's a privacy issue.

Don: the problem is in cases where privacy principles say consent isn't needed, the lawyer says consent is needed but we can get away with sneaky consent

Jeffrey: there' sa risk there'll build the sneaky consent flow an duse it in other places. I agree that's a risk but I think we should still say privacy wise this doesn't need consent or does, and when there's a privacy reason you should do fair consent, and then shake our fingers at sites that use their consent in bad ways

Nick: lots of abuse things we can't speak to. Is there an action to take here?

Don: I'll reread and talk about no consent or fair consent, sneaky consent is never appropriate even if we don't think consent is needed.
