# TAG Privacy TF - Wed, 7 September 2022

present: Don, Jeffrey, Robin, Peter, Dan, Nick
regrets: christine, amy, wendy, shubhie


## Add a principle to support deception #181

[discussion on balance]

Jeffrey: anti-fraud people won't like "deception"; do you want me to ask them to propose a compromise

Nick: we discussed not explicitly talking about deceoption if we talk aboUT APIs not being used to assert truth.

Pete: I like ... thinking through the legalcy APIs.

Robin: i think we can come up with a [balanced] approach.

## 177

Pete: seems to say UAs might help ... current version says UAs *will* seems unappealing from a privacy perspective.  I still think it is the case after a close read.

Jeffrey: I think going back to *should* or *can* is totally fine here.  UAs can make different decisions.

*going through some editorial comments from Robin*

Dan: Timing attacks...

Robin: kind of attack I'm worried about - you click on their site to exit it and it loads a page with whatever code .. matches the timing and it uses 1st party cookies...

Jeffrey: correlating timestamps ...  timing attacks is really broad...

Dan: So add a parenthetical?

Pete: ephemeral fingerprinting... larhe list of ways... 

Nick: I agree that it's a good reference and an overloading of the term...

Robin: in the editorial pass we link - in the section we say it's a type of timing attack and we also reference the doc from Pete.

## 170

Nick: haven't split it up.. Jeffrey has made some comments about relational governance...?

Jeffrey: my understanding ... data has effects across multiple people... use of that data can be either good or bad.  Privacy people focus on the bad aspects.  there are places where collecting data -- where collecting it is good enough for society that we want to do it.  Telemetry data is I think an example of that. Most of the time it doesn't harm an individual user... but enough collective benefit ... 

Don: ...one of those rare examples where consent appropriate...

Jeffrey: bugging users every time weant to send to telemetry might be causing harm.. Some input from users. The W3C .. we can get input from the right groups.  We could say "when there is a collective benefit you should go to an open standards body" and "users should still have control over it - this is for the default"

Don: I was thinking of browser telemetry and browser assisted mutliparty computation...  "Yes I want to provide aggregated QA data and willing to give it to sites that follow this cryptographic telemetry protocol - might consent to it once when i set up my new browser - but any thing beyond that  would require more consent" (example: Prio)

Jeffrey: plausable.

Pete: Just because these exist doesn't imply this is one of those cases... a mismatch - users pay the cost of benefiting the collective of sites... I suggested a checkbox when you install the browser..  some way of ensuring consent seems important.  Not pushing a particular flow - just want to ensure users agree. I don't agree w3c is a proxy for a democratic collective... the user's voice.  would feel a lot less worried if there was some language about what the bounds are.  how much can people be conscripted for a collective benefit? "things users want their browsers to do" as an example.

Nick: I think 2 potential areas - 1. we have a collective governance section... seems like a similar point. some decisions individuals aren't in a good position to make or some collective benefit or some cases where the individual who could be harmed isn't in the decision flow. could we integrate that into that section. That seems separate from 2. there can be a duty of loyalty for users but because users don't take the time to understand the details.. users don't make a case-by-case decision. So how can you have a duty of loyalty to users without bothering them? Let's try to get text on that that's separate from the collective [governance] question.

Jeffrey: that makes sense... I will double check with performance people... asking telemetry to the install process makes sense... there is some collective governance that needs to happen.  List of ancilary usses seems like a good starting point.  

Nick: I'll need to clarify ... the types of data... 

Robin: lots of good points... we need a balancing test.  What you use when you make decisions on behalf of data subjects.  A lot of what goes into balancing tests is what Pete is talking about... e.g. under GDRP you look at risks to the data subjects... what controls you have, etc... e.g. you should never have access to an IP address for telemetry... some things we can enforce at the browser level and some not. One thing to explore: is there a world in which we ...

Dan: brittle to build policy into code...

Robin: not necessarilly... balancing test result might lead to minor harm... 

Dan: design principles implications for APIs that collect telemetry

Don: consent implies that you know the party you're consenting to.. not sure if you can have consent to a party to be determined later. or could be a browser preference. "I have a preference to allow my info to be used in such a way that it's cryptomagically prevented from being sale or processing of my data... but still technical consent" but realize this consent is not *legal* consent. Bigger issue of a legal / standards interaction issue. Consent has a specific meaning under GDPR.

Nick: useful to avoid "consent" .. "consented data" is not a thing. More fruitful direction is purpose specification.. maybe we accept that it was right to say policy shouldn't be with data ... but APIs can have a purpose.  We make sure it's focused on the use case and not have alt functionality which can be abused. Maybe a purpose specification concept in addition to data minimization.  Maybe APIs should be more purpose specific and these will be concepts that help protect privacy...

